# Configuration file documentation for KernelHaven
#
# This file lists all known configuration options that are available for
# KernelHaven. Note that some plugins may define their own settings, that are
# not listed in this file. However, this file should cover the most common
# plugins.
#
# This configuration file is a standard Java Properties file (see the
# documentation of java.util.Properties). A properties file is a key-value
# storage in the format: key = value. Lines starting with a hash (#) are
# comments and not considered in parsing. Multiple lines can be joined together
# with a backslash (\) character directly in front of the line break. This is
# useful for multi-line values or formatting.
#
# This file lists the keys for the settings defined in the main infrastructure,
# followed by the settings of common plugins. Each setting has a short
# description, that contains:
#  * An explanation text for the setting.
#  * The type of setting (see below for a list possible types).
#  * For enums: The possible values.
#  * The default value for the setting, if it specifies one.
#  * If no default value is specified: Whether the setting is mandatory or not.
#
# Possible setting types are:
#  * String: A simple text value.
#  * Integer: An integer value. An exception is generated if this is not a valid
#             integer.
#  * Boolean: A boolean value. Everything except "true" (case insensitive) is
#             considered to be the value false.
#  * Regular Expression: A Java regular expression. See the documentation for
#                        java.util.regex.Pattern class.
#  * Path: A path value. The file denoted by this does not have to exist.
#  * Existing File: A path value for an existing file. If the specified file
#                   does not exist, then an exception is thrown. This can either
#                   be absolute, relative to the current working directory or
#                   relative to the source_tree setting (first file found in
#                   this order is used).
#  * Existing Directory: A path value for an existing directory. If the
#                        specified directory does not exist, then an exception
#                        is thrown. This can either be relative to the current
#                        working directory or an absolute path.
#  * Enum: One value of an enumartion of possible values. Not case sensitive.
#  * Comma separated list of strings: A comma separated list of string values.
#  * List of setting keys: A list of string values created from multiple setting
#                          keys. The base key is appended by a .0 for the first
#                          value. The following values increase this integer.
#                          For example:
#                            key.0 = a
#                            key.1 = b
#                            key.2 = c
#                          Defines the list ["a", "b", "c"].
#
# This was automatically generated on: 2018-10-02 15:38:29

#######################
# Main Infrastructure #
#######################

# Specifies another property file, that is loaded as a base configuration before
# the file that this setting appears in. The file specified here is loaded
# first; if the same key appears in both files (included and including), then
# the value in the including file overwrites the value loaded in the included
# file. The path in here is relative to the configuration file that this setting
# appears in.
#
# Type: Existing File
# Mandatory: No
include_file =

# The path where extractors can store their resources. The extractors create
# sub-folders in this called the same as their fully qualified class names (to
# prevent conflicts). This has to be always set to a valid directory with write
# and read access.
#
# Type: Existing Directory
# Mandatory: Yes
resource_dir =

# The path where the output files of the analysis will be stored. This has to be
# always set to a valid directory with write access.
#
# Type: Existing Directory
# Mandatory: Yes
output_dir =

# The path where plugin .jars are loaded from. Every .jar in this directory is
# loaded into the JVM. This has to be always set to a valid directory with read
# access.
#
# Type: Existing Directory
# Mandatory: Yes
plugins_dir =

# This is the directory where the providers will write and read their cache.
# This has to be set to a valid directory with write and read access.
#
# Type: Existing Directory
# Mandatory: Yes
cache_dir =

# The path where log files will be written. This has to be set to a valid
# directory with write access.
#
# Type: Existing Directory
# Default value: .
log.dir =

# Directory to write the archive of the infrastrucure execution to. This has to
# be set to a valid directory with write access.
#
# Type: Existing Directory
# Default value: .
archive.dir =

# If set to true all log messages will be written to console.
#
# Type: Boolean
# Default value: true
log.console =

# If set to true all log messages will be written to a file in the log
# directory.
#
# Type: Boolean
# Default value: false
log.file =

# Defines the maximum log level to log.
#
# Type: Enum
# Possible values: NONE, ERROR, WARNING, STATUS, INFO, DEBUG
# Default value: INFO
log.level =

# Overrides whether ANSI color codes should be used when logging to stdout. By
# default, it is automatically detected whether to use color or not (ANSI color
# codes are used on non-Windows operating systems and if output has not been
# redirected).
#
# Type: Boolean
# Mandatory: No
log.force_color =

# If set to true the infrastructure will archive itself, plugins, results,
# configuration and logs after the execution is finished. Alternative to the
# --archive command line parameter.
#
# Type: Boolean
# Default value: false
archive =

# Defines whether the source tree should be included in the archive.
#
# Type: Boolean
# Default value: false
archive.source_tree =

# Defines whether the cache directory should be included in the archive.
#
# Type: Boolean
# Default value: false
archive.cache_dir =

# Defines whether the ressource directory should be included in the archive.
#
# Type: Boolean
# Default value: false
archive.res_dir =

# The fully qualified class name of the analysis that should be run.
#
# Type: String
# Mandatory: Yes
analysis.class =

# Specifies which analysis components (simple class name) of a PipelineAnalysis
# should output their intermediate results. These will be written in addition to
# the result of the main component.
#
# Type: Comma separated list of strings
# Default value: (empty string)
analysis.output.intermediate_results =

# A string specifying a pipeline of analyis components. This only has an effect
# if analysis.class is set to
# net.ssehub.kernel_haven.analysis.ConfiguredPipelineAnalysis.
#
# Type: String
# Default value: (empty string)
analysis.pipeline =

# A file suffix that specifies which kind of output writer shall be used. By
# deafult, the main infrastructure supports "csv" and "csv.zip". If IOUtils is
# used, then "xls" or "xlsx" can be used here.
#
# Type: String
# Default value: csv
analysis.output.type =

# Defines whether the analysis should only consider variables that are present
# in the variability model.
#
# Type: Boolean
# Default value: false
analysis.consider_vm_vars_only =

# Whether the analysis pipeline should preemptively start all three extractors.
# This has the advantage that the extractors will always run in parallel, even
# if the analysis compoenents only poll them in order. If this is set to false,
# then the extractors only start on demand when the analysis components poll
# them.
#
# Type: Boolean
# Default value: true
analysis.pipeline.preemptively_start_extractors =

# If greater than 0, a thread pool is used to limit the maximum number of
# threads executed in parallel when joining the results via the
# net.ssehub.kernel_haven.analysis.SplitComponent.
#
# Type: Integer
# Default value: 0
analysis.splitcomponent.max_parallel_threads =

# The path to the source tree of the product line that should be analyzed.
#
# Type: Existing Directory
# Mandatory: Yes
source_tree =

# The architecture of the Linux Kernel that should be analyzed. Most Linux
# extractors require this.
#
# Type: String
# Mandatory: No
arch =

# The fully qualified class name of the extractor for the code model.
#
# Type: String
# Default value: net.ssehub.kernel_haven.code_model.EmptyCodeModelExtractor
code.extractor.class =

# The maximum time the provider waits for the results of the extractor until an
# exception is thrown. In milliseconds; 0 = no timeout used.
#
# Type: Integer
# Default value: 0
code.provider.timeout =

# Defines whether the code model provider will write its results to the cache
# directory.
#
# Type: Boolean
# Default value: false
code.provider.cache.write =

# Defines whether the code model provider is allowed to read the cache instead
# of starting the extractor.
#
# Type: Boolean
# Default value: false
code.provider.cache.read =

# Whether the individual cache files for the code model should written as
# compressed Zip archives. Reading of compressed cache files is always
# supported.
#
# Type: Boolean
# Default value: false
code.provider.cache.compress =

# Defines which files the code extractor should run on. Comma separated list of
# paths relative to the source tree. If directories are listed, then they are
# searched recursively for files that match the regular expression specified in
# code.extractor.file_regex. Set to an empty string to specify the complete
# source tree.
#
# Type: Comma separated list of strings
# Default value: (empty string)
code.extractor.files =

# A Java regular expression defining which files are considered to be source
# files for parsing. See code.extractor.files for a description on which files
# this expression is tested on.
#
# Type: Regular Expression
# Default value: .*\.c
code.extractor.file_regex =

# The number of threads the code extractor should use. This many files are
# parsed in parallel.
#
# Type: Integer
# Default value: 1
code.extractor.threads =

# Defines whether non-boolean conditions that are encountered in the code should
# be (fuzzily) convereted into boolean conditions, instead of throwing an
# exception. For example, this replaces (A == 1) && B with A_eq_1 && B.
#
# Type: Boolean
# Default value: false
code.extractor.fuzzy_parsing =

# The fully qualified class name of the extractor for the build model.
#
# Type: String
# Default value: net.ssehub.kernel_haven.build_model.EmptyBuildModelExtractor
build.extractor.class =

# The maximum time the provider waits for the results of the extractor until an
# exception is thrown. In milliseconds; 0 = no timeout used.
#
# Type: Integer
# Default value: 0
build.provider.timeout =

# Defines whether the build model provider will write its results to the cache
# directory.
#
# Type: Boolean
# Default value: false
build.provider.cache.write =

# Defines whether the code model build is allowed to read the cache instead of
# starting the extractor.
#
# Type: Boolean
# Default value: false
build.provider.cache.read =

# A Java regular expression defining which files are considered to be files
# relevant for parsing the build model.
#
# Type: Regular Expression
# Default value: .*(?i)(^|\/|\\)(Makefile\.?\w*|Kbuild|Build)
build.extractor.file_regex =

# The fully qualified class name of the extractor for the variability model.
#
# Type: String
# Default value: net.ssehub.kernel_haven.variability_model.EmptyVariabilityModelExtractor
variability.extractor.class =

# The maximum time the provider waits for the results of the extractor until an
# exception is thrown. In milliseconds; 0 = no timeout used.
#
# Type: Integer
# Default value: 0
variability.provider.timeout =

# Defines whether the variability model provider will write its results to the
# cache directory.
#
# Type: Boolean
# Default value: false
variability.provider.cache.write =

# Defines whether the variability model provider is allowed to read the cache
# instead of starting the extractor.
#
# Type: Boolean
# Default value: false
variability.provider.cache.read =

# Path of a single file to be parsed by a variability model extractor.
#
# Type: Existing File
# Mandatory: No
variability.input.file =

# A Java regular expression defining which files are considered to be source
# files relevant for parsing the variability model.
#
# Type: Regular Expression
# Default value: ..*(?i)(^|\/|\\)(Kconfig)
variability.extractor.file_regex =

# A list of fully qualified class names that defines which preparations to run.
# A preparation class has to implement IPreperation. The preparations defined
# here are executed in the defined order.
#
# Type: List of setting keys
# Mandatory: No
preparation.class.0 =

############
# CnfUtils #
############

# Defines which SAT solver to use.
#
# Type: Enum
# Possible values: SAT4J, CRYPTOMINISAT
# Default value: SAT4J
cnf.solver =

###################
# NonBooleanUtils #
###################

# The destination directory where a temporary copy of the source tree with the
# non boolean replacements should be placed. All contents of this will be
# overwritten.
#
# Type: Existing Directory
# Mandatory: Yes
prepare_non_boolean.destination =

# A regular expression to define what the variables that require non-boolean
# replacements look like. This regex should also cover the names of the constant
# variables, that should be replaced by their value.
#
# Type: Regular Expression
# Mandatory: Yes
code.extractor.variable_regex =

#########################
# FeatureEffectAnalysis #
#########################

# Defines a regular expression that specifies which variables should be present
# in the output.
#
# Type: Regular Expression
# Default value: .*
analysis.relevant_variables =

# Specifies whether and and which analysis step, results should be simplified:
#  - NO_SIMPLIFICATION: Won't simplifiy results.
#  - PRESENCE_CONDITIONS: Will simplifiy (indermediate) results of presence
#    condition detection and all later steps.
#  - FEATURE_EFFECTS: Will simplifiy the results of the feature effect
# analysis.
#
# Type: Enum
# Possible values: NO_SIMPLIFICATION, PRESENCE_CONDITIONS, FEATURE_EFFECTS
# Default value: NO_SIMPLIFICATION
analysis.simplify_conditions =

# Location an historical SPL configuration file, which should be analyses
# w.r.t.the relevance of the configured variables.
#
# Type: Existing File
# Mandatory: Yes
analysis.config_relevancy_checker.configuration_file =

# A file containing the feature effects to be read by the
# net.ssehub.kernel_haven.fe_analysis.fes.FeatureEffectReader
#
# Type: Existing File
# Mandatory: Yes
analysis.feature_effect.file =

# Whether the net.ssehub.kernel_haven.fe_analysis.pcs.PcFinder should consider
# all presence conditions from the build model. If true, then all PCs from the
# build model will be considered, even if no real file for it exists.
#
# Type: Boolean
# Default value: false
analysis.pc_finder.add_all_bm_pcs =

# A file containing the presence conditions to be read by the
# net.ssehub.kernel_haven.fe_analysis.pcs.PcReader
#
# Type: Existing File
# Mandatory: Yes
analysis.presence_conditions.file =

###############
# MetricHaven #
###############

# Defines the file that
# net.ssehub.kernel_haven.metric_haven.filter_components.scattering_degree.ScatteringDegreeReader
# and
# net.ssehub.kernel_haven.metric_haven.filter_components.scattering_degree.ScatteringDegreeWriter
# read and write the scattering degree cache to.
#
# Type: Path
# Mandatory: No
metrics.sd_cache.file =

# Defines the number of threads to use for calculating metrics. Must be >= 1.
#
# Type: Integer
# Default value: 1
metrics.max_parallel_threads =

# If turned on, results will be limited to 2 digits after the comma (0.005 will
# be rounded up). This is maybe neccessary to limit the disk usage.
#
# Type: Boolean
# Default value: false
metrics.round_results =

# Defines a list of fully qualified class names of metrics that the
# net.ssehub.kernel_haven.metric_haven.metric_components.CodeMetricsRunner
# component should execute.
#
# Type: Comma separated list of strings
# Mandatory: No
metrics.code_metrics =

# If defined, the results are filter so that the final results will contain only
# results for the specified files (comma separated list)
#
# Type: Comma separated list of strings
# Mandatory: No
metrics.filter_results_by.files =

# Specifies, the files and line numbers that the CodeFunctionByLineFilter should
# filter the code functions for. Each element in the list should have a colon
# separated file path and line number (e.g. kernel/kernel.c:51 for line 51 in
# the file kernel/kernel.c). File paths are relative to the source tree. The
# filter will pass on only the functions that contain one of the file and line
# number pairs.
#
# Type: Comma separated list of strings
# Mandatory: No
analysis.code_function.lines =

# Specifies whether to run allvariations of a metric in parallel (true) or only
# a single variation (false). If not specified, all variations will be measured
# by default.
#
# Type: Boolean
# Default value: true
metrics.function_measures.all_variations =

# Defines whether and how to incorporate scattering degree valuesinto
# measurement results.
#  - NO_SCATTERING: Do not consider scattering degree (default).
#  - SD_VP: Use variation point scattering.
#  - SD_FILE: Use filet scattering.
#
# Type: Enum
# Possible values: NO_SCATTERING, SD_VP, SD_FILE
# Default value: NO_SCATTERING
metrics.function_measures.consider_scattering_degree =

# Defines whether and how to incorporate cross-tree constraint ratios from the
# variability model into measurement results.
#  - NO_CTCR: Do not consider any cross-tree constraint ratios (default).
#  - INCOMIG_CONNECTIONS: Count number of distinct variables, specifying a
#    constraint TO a measured/detected variable.
#  - OUTGOING_CONNECTIONS: Count number of distinct variables, referenced in
#    constraints defined by the measured/detected variable.
#  - ALL_CTCR: Count number of distinct variables in all constraints connected
#    with the measured/detected variable (intersection of INCOMIG_CONNECTIONS
#    and OUTGOING_CONNECTIONS.
#
# Type: Enum
# Possible values: NO_CTCR, OUTGOING_CONNECTIONS, INCOMIG_CONNECTIONS, ALL_CTCR
# Default value: NO_CTCR
metrics.function_measures.consider_ctcr =

# Defines whether and how to incorporate distance between used feature (location
# of measured code file) and definition of feature (defining file of variability
# model):
#  - NO_DISTANCE: Do not consider any distances (default).
#  - SHORTEST_DISTANCE: Count the minimum number of required folder changes to
# traverse to the defining file.
#
# Type: Enum
# Possible values: NO_DISTANCE, SHORTEST_DISTANCE
# Default value: NO_DISTANCE
metrics.function_measures.consider_feature_definition_distance =

# Defines whether and how to incorporate types of used features:
#  - NO_TYPE_MEASURING: Do not consider any types (default).
#  - TYPE_WEIGHTS_BY_FILE: Weights are defined in the configuration file.
#
# Type: Enum
# Possible values: NO_TYPE_MEASURING, TYPE_WEIGHTS_BY_FILE
# Default value: NO_TYPE_MEASURING
metrics.function_measures.consider_feature_types =

# Defines the weights to be used if
# metrics.function_measures.consider_feature_types is set to
# TYPE_WEIGHTS_BY_FILE
# Define the weights in form of (separated by a comma): type:weight
#
# Type: Comma separated list of strings
# Mandatory: No
metrics.function_measures.type_weight_definitions =

# Defines whether and how to incorporate hierarchies of used features:
#  - NO_HIERARCHY_MEASURING: Do not consider any hierarchies (default).
#  - HIERARCHY_WEIGHTS_BY_FILE: Weights are defined in the configuration file.
#  - HIERARCHY_WEIGHTS_BY_LEVEL: The hierarchy (level) is directly used as
# weight.
#
# Type: Enum
# Possible values: NO_HIERARCHY_MEASURING, HIERARCHY_WEIGHTS_BY_FILE, HIERARCHY_WEIGHTS_BY_LEVEL
# Default value: NO_HIERARCHY_MEASURING
metrics.function_measures.consider_feature_hierarchies =

# Defines the weights to be used if
# metrics.function_measures.consider_feature_hierarchies is set to
# HIERARCHY_WEIGHTS_BY_FILE
# Define the weights in form of (separated by a comma): hierarchy:weight
#
# Type: Comma separated list of strings
# Mandatory: No
metrics.function_measures.hierarchy_weight_definitions =

# Defines whether and how to incorporate stucturalinformation of used features:
#  - NO_STRUCTURAL_MEASUREMENT: Do not consider any structures (default).
#  - NUMBER_OF_CHILDREN: Count number of children (inspired by RoV).
#  - COC: Count all edges (inspired by CoC).
#
# Type: Enum
# Possible values: NO_STRUCTURAL_MEASUREMENT, NUMBER_OF_CHILDREN, COC
# Default value: NO_STRUCTURAL_MEASUREMENT
metrics.function_measures.consider_varmodel_structures =

# Defines whether partial blocks (#elif/#else) are also counted.
#
# Type: Enum
# Possible values: BLOCK_AS_ONE, SEPARATE_PARTIAL_BLOCKS
# Default value: BLOCK_AS_ONE
metrics.blocks_per_function.measured_block_type =

# Defines which lines of code should be counted for a function:
#  - DLOC: Counts all statements, i.e., all delivered Lines of Code
#    (dLoC).
#  - LOF: Counts all variable statements, sometimes refereed to as Lines
#    of Feature code (LoF).
#  - PLOF: Computes the fraction of LoF/dLoC (0 if LoF is 0).
#
# Type: Enum
# Possible values: DLOC, LOF, PLOF
# Default value: DLOC
metrics.loc.measured_type =

# Defines which type of fan in/out should be counted for a function.
#
# Type: Enum
# Possible values: CLASSICAL_FAN_IN_GLOBALLY, CLASSICAL_FAN_IN_LOCALLY, CLASSICAL_FAN_OUT_GLOBALLY, CLASSICAL_FAN_OUT_LOCALLY, VP_FAN_IN_GLOBALLY, VP_FAN_IN_LOCALLY, VP_FAN_OUT_GLOBALLY, VP_FAN_OUT_LOCALLY, DEGREE_CENTRALITY_IN_GLOBALLY, DEGREE_CENTRALITY_IN_LOCALLY, DEGREE_CENTRALITY_OUT_GLOBALLY, DEGREE_CENTRALITY_OUT_LOCALLY
# Default value: CLASSICAL_FAN_IN_GLOBALLY
metrics.fan_in_out.type =

# Defines which variables should be counted for a function.
#
# Type: Enum
# Possible values: MCCABE, VARIATION_POINTS, ALL
# Default value: MCCABE
metrics.cyclomatic_complexity.measured_type =

# Defines what should be counteded as the nesting depth:
#  - CLASSIC_ND_MAX: Counts the max. nesting depth w.r.t classical
#    control structures.
#  - CLASSIC_ND_AVG: Counts the avg. nesting depth w.r.t classical
#    control structures.
#  - VP_ND_MAX: Counts the max. nesting depth w.r.t variation points
#    (CPP-blocks).
#  - VP_ND_AVG: Counts the avg. nesting depth w.r.t variation points
#    (CPP-blocks).
#  - COMBINED_ND_MAX: CLASSIC_ND_MAX + VP_ND_MAX
#  - COMBINED_ND_AVG: CLASSIC_ND_AVG + VP_ND_AVG
#
# Type: Enum
# Possible values: CLASSIC_ND_MAX, CLASSIC_ND_AVG, VP_ND_MAX, VP_ND_AVG, COMBINED_ND_MAX, COMBINED_ND_AVG
# Default value: CLASSIC_ND_MAX
metrics.nesting_depth.measured_type =

# Defines which variables should be counted for a function.
#
# Type: Enum
# Possible values: INTERNAL, EXTERNAL, EXTERNAL_WITH_BUILD_VARS, ALL, ALL_WITH_BUILD_VARS
# Default value: ALL
metrics.variables_per_function.measured_variables_type =

##################
# UnDeadAnalyzer #
##################

# Defines the type of missing analysis to execute.
#
# Type: Enum
# Possible values: DEFINED_BUT_NOT_USED, USED_BUT_NOT_DEFINED
# Default value: DEFINED_BUT_NOT_USED
analysis.missing.type =

# Number of threads to use for the
# net.ssehub.kernel_haven.undead_analyzer.ThreadedDeadCodeFinder. Must be >= 1.
#
# Type: Integer
# Default value: 2
analysis.undead.threads =

########################
# KbuildMinerExtractor #
########################

# List of top-folders to analyze in the product line. If this is not specfied,
# it is automatically generated from the arch setting.
#
# Type: String
# Mandatory: No
build.extractor.top_folders =

##########################
# KconfigReaderExtractor #
##########################

# TODO
#
# Type: Enum
# Possible values: LINUX, BUSYBOX
# Default value: LINUX
variability.extractor.dumpconf_version =

# If set to true, the extractor will store source locations for each variable.
# Those locations represent occurences of the variable in the files that
# kconfigreader used for generating the VariabilityModel.
#
# Type: Boolean
# Default value: false
variability.extractor.find_locations =

##################
# SrcMlExtractor #
##################

# How #include directives should be handled.
# 
# - IGNORE: Does nothing; leaves the #include directives as preprocessor
# statements in the AST.
# - INCLUDE: Parses the headers and includes their AST instead of the #include
# directive.
# - EXPAND_FUNCTION_CONDITION: Includes headers like INCLUDE. Searches for
# declarations of functions in the headers. If declarations for the functions
# that are implemented in the C file are found, then their conditions are
# expanded by the condition of the declaration.
# 
# Currently only quote include directives (#include "file.h") relative to the
# source file being parsed are supported.
#
# Type: Enum
# Possible values: IGNORE, EXPAND_FUNCTION_CONDITION, INCLUDE
# Default value: IGNORE
code.extractor.header_handling =

#####################
# TypeChefExtractor #
#####################

# TODO
#
# Type: Boolean
# Default value: false
code.extractor.ignore_other_models =

# Specifies the granularity of the translation result:
#  - LEXER: Stops the translation after the lexer and returns a flat list of
# presence
#    conditions only
#  - ONLY_C_AST: Translates the content of the C-Code only. This includes also
#    embedded macro class of a C-functions. However, this will skip all
#    header-specific elements, which are not nested inside a C-code element.
#    For instance, these may be structs or function declarations.
#  - FULL_AST: These will generate a full AST. This will also include
# definitions
#    of included headers, even if this code is not embedded in C-code. This
#    facilitates more detailed analyses like data flow analysis. However, this
#    approach is significantly slower (~ 2x) and requires significantly more
# hard
#    drive space (~ 40x) if the result is cached, with respect to ONLY_C_AST.
#
# Type: Enum
# Possible values: FULL_AST, ONLY_C_AST, LEXER
# Mandatory: Yes
code.extractor.parse_type =

# TODO
#
# Type: Existing Directory
# Default value: /
code.extractor.system_root =

# TODO
#
# Type: Boolean
# Default value: false
code.extractor.skip_default_include_dirs =

# TODO
#
# Type: String
# Default value: 15g
code.extractor.process_ram =

# TODO
#
# Type: List of setting keys
# Mandatory: No
code.extractor.static_include.0 =

# TODO
#
# Type: List of setting keys
# Mandatory: No
code.extractor.post_include_dir.0 =

# TODO
#
# Type: List of setting keys
# Mandatory: No
code.extractor.source_include_dir.0 =

# TODO
#
# Type: Boolean
# Default value: false
code.extractor.add_linux_source_include_dirs =

# TODO
#
# Type: List of setting keys
# Mandatory: No
code.extractor.preprocessor_define.0 =

# TODO
#
# Type: Existing File
# Mandatory: No
code.extractor.kbuildparam_file =

# TODO
#
# Type: Existing File
# Mandatory: No
code.extractor.platform_header =

# TODO
#
# Type: Existing File
# Mandatory: No
code.extractor.open_variables =

# TODO
#
# Type: Existing File
# Mandatory: No
code.extractor.small_feature_model =

# TODO
#
# Type: Integer
# Default value: 0
code.extractor.max_receiving_threads =

# TODO
#
# Type: Boolean
# Default value: false
code.extractor.debug.call_in_same_vm =

# TODO
#
# Type: Boolean
# Default value: false
ode.extractor.debug.log_call_params =

# TODO
#
# Type: Boolean
# Default value: false
code.extractor.debug.inherit_output =

#######################
# UndertakerExtractor #
#######################

# Undertaker has a bug where it hangs forever on some few files of the Linux
# Kernel. This setting defines a timeout in milliseconds until the undertaker
# executable is forcibly terminated.
#
# Type: Integer
# Default value: 20000
code.extractor.hang_timeout =

######################
# CodeBlockExtractor #
######################

# How to handle conditions of blocks that are invalid or not parseable.
# 
# - EXCEPTION: Throw an exception. This causes the whole file to not be
# parseable.
# - TRUE: Replace the invalid condition with true.
# - ERROR_VARIABLE: Replace the invalid condition with a variable called
# "PARSING_ERROR"
#
# Type: Enum
# Possible values: EXCEPTION, TRUE, ERROR_VARIABLE
# Default value: EXCEPTION
code.extractor.invalid_condition =

# Whether to handle the preprocessor macros IS_ENABLED, IS_BUILTIN and IS_MODULE
# in preprocessor block conditions.
#
# Type: Boolean
# Default value: false
code.extractor.handle_linux_macros =
